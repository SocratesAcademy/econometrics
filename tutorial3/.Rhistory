pagedown::chrome_print("tutorial3.html",output="tutorial3.pdf")
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, dpi = 200, fig.width = 8, fig.height = 5)
library(tidyverse)
library(estimatr)
library(dagitty)
library(ggdag)
library(fixest)
library(jtools)
library(scales)
library(Cairo)
library(vtable)
library(modelsummary)
theme_metro <- function(x) {
theme_classic() +
theme(panel.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
plot.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
text = element_text(size = 16),
axis.title.x = element_text(hjust = 1),
axis.title.y = element_text(hjust = 1, angle = 0))
}
theme_void_metro <- function(x) {
theme_void() +
theme(panel.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
plot.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
text = element_text(size = 16))
}
theme_metro_regtitle <- function(x) {
theme_classic() +
theme(panel.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
plot.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
text = element_text(size = 16))
}
# create vectors to store your estimates
coef_results <- c()
sig_results <- c()
set.seed(777)
# create vectors to store your estimates
coef_results <- c()
sig_results <- c()
for (i in 1:500) {
# have to re-create the data every time or it will just be the same data
df <- tibble(D = runif(1000, 0, 1),
Y = 0*D + rnorm(1000, mean = 0, sd = 3))
# Run the analysis
model <- feols(Y ~ D, df, se = 'hetero')
# Get the results
coef_results[i] <- coef(model)[2]
sig_results[i] <- tidy(model)$p.value[2] <= .05
}
mean(sig_results)
results_tibble <- tibble(coef = coef_results, sig = sig_results)
ggplot(results_tibble, aes(x = coef)) +
geom_density() +
theme_minimal() +
labs(x = 'Coefficient', y = 'Density')
ggplot(results_tibble, aes(x = sig)) +
geom_bar() +
theme_minimal() +
labs(x = 'Coefficient', y = 'Count') +
scale_x_discrete(labels = c('Insignificant','Significant'))
my_power_function <- function(effect, sample_size) {
sig_results <- c()
for (i in 1:500) {
# Have to re-create the data EVERY TIME or it will just be the same data
df <- tibble(D = runif(sample_size, 0, 1),
Y = effect*D + rnorm(sample_size, mean = 0, sd = 3))
# Run the analysis
model <- feols(Y ~ D, data = df, se = 'hetero')
# Get the results
sig_results[i] <- tidy(model)$p.value[2] <= .05
}
sig_results %>%
mean() %>%
return()
}
my_power_function(0, 1000)
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, dpi = 200, fig.width = 8, fig.height = 5)
library(tidyverse)
library(gganimate)
library(estimatr)
library(magick)
library(dagitty)
library(ggthemes)
library(directlabels)
library(ggdag)
library(jtools)
library(scales)
library(Cairo)
library(modelsummary)
library(stargazer)
theme_metro <- function(x) {
theme_classic() +
theme(panel.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
plot.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
text = element_text(size = 16),
axis.title.x = element_text(hjust = 1),
axis.title.y = element_text(hjust = 1, angle = 0))
}
theme_void_metro <- function(x) {
theme_void() +
theme(panel.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
plot.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
text = element_text(size = 16))
}
theme_metro_regtitle <- function(x) {
theme_classic() +
theme(panel.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
plot.background = element_rect(color = '#FAFAFA',fill='#FAFAFA'),
text = element_text(size = 16))
}
# Always set seed so you can replicate your results
set.seed(7)
df <- tibble(education = runif(1000, 5, 15),
wage_star = 1000 + 200*education + rnorm(1000, 0, 100),
wage = ifelse(wage_star > 3500, 3500, wage_star))  %>%
arrange(desc(wage_star))
View(df)
library(fixest)
df <- tibble(groups = sort(rep(1:10, 600)),
time = rep(sort(rep(1:6, 100)), 10),
Treated = I(groups > 5) * I(time > 3),
Y = groups + time + Treated * 5 + rnorm(6000))
did <- feols(Y ~ Treated | groups + time, data = df)
# Always set seed so you can replicate your results
set.seed(7)
df <- tibble(education = runif(1000, 5, 15),
wage_star = 1000 + 200*education + rnorm(1000, 0, 100),
wage = ifelse(wage_star > 3500, 3500, wage_star))  %>%
arrange(desc(wage_star))
```{r, echo = FALSE}
df %>%
slice(c(1:3, 997:1000)) %>%
knitr::kable()
ols_model <- lm(wage ~ education, df)
msummary(ols_model, stars = TRUE,  gof_omit = '^(?!Num)')
library(censReg)
tobit_model <- censReg(wage ~ education, data = df, right = 3500)
library(censReg)
tobit_model <- censReg(wage ~ education, data = df, right = 3500)
library(censReg)
msummary(tobit_model, stars = TRUE,  gof_omit = '^(?!Num)')
msummary(tobit_model, stars = TRUE,  gof_omit = '^(?!Num)', coef_omit = "(Intercept)")
msummary(tobit_model, stars = TRUE,  gof_omit = '^(?!Num)')
ggplot(df, aes(x = education, y = wage)) +
theme_light() +
geom_point(aes(color = 'dark grey')) +
geom_abline(color = 'red', intercept = ols_model[["coefficients"]][["(Intercept)"]], slope = ols_model[["coefficients"]][["education"]]) +
geom_abline(color = 'blue', intercept = tobit_model[["estimate"]][["(Intercept)"]], slope = tobit_model[["estimate"]][["education"]]) +
scale_color_manual(name = "", values = c("Observed data" = "dark grey",
"OLS" = "red",
"Tobit" = "blue"))
library(mvtnorm) # to simulate bivariate normal random variable
set.seed(7)
df <- tibble(z = runif(1000),
x = runif(1000),
uv = rmvnorm(1000, mean = c(0, 0),
sigma = rbind(c(1, 0.7), c(0.7, 1))),
i_star = 4 - 5 * z + uv[, 1],
y_star = 6 - 3 * x + uv[, 2],
# this is our selection mechanism
y = ifelse(i_star > 0, y_star, 0))
selection_equation <- glm(I(y > 0) ~ z, df, family = binomial(link = "probit"))
wage_equation <- lm(y ~ x, df)
msummary(list(selection_equation, wage_equation), stars = TRUE, gof_omit = '^(?!Num)')
set.seed(7)
df <- tibble(v = rnorm(1000),
z2 = -v + rnorm(1000),
u2 = 0.1*v + rnorm(1000),
# we only change the coefficient for z2 in the equation for x3
x3 = 3*z2 + 4*u2 + rnorm(1000),
y2 = 3*x3 + 5*u2)
# The true effect is 3
iv_model3 <- feols(y2 ~ 1 | x3 ~ z2, data = df, se = 'hetero')
ols_model3 <- lm(y2 ~ x3, df)
thef <- fitstat(iv_model3, 'ivf', verbose = FALSE)$`ivf1::x3`$stat
fitstat(iv_model3, 'ivf', verbose = FALSE)$`ivf1::x3`$stat
View(iv_model3)
?fitstat
fitstat(iv_model3, 'ivf')$`ivf1::x3`$stat
fitstat(iv_model3, 'ivf')$`ivf1::x3`$stat
fitstat(iv_model3, 'ivf')
thef <- fitstat(iv_model3, 'ivf')
View(thef)
thef <- fitstat(iv_model3, 'ivf')[["ivf1::x3"]][["stat"]]
thef
fitstat(iv_model3, 'ivf')
fitstat(iv_model3)
# Always set seed so you can replicate your results
set.seed(7)
df <- tibble(education = runif(1000, 5, 15),
wage_star = 1000 + 200*education + rnorm(1000, 0, 100),
wage = ifelse(wage_star > 3500, 3500, wage_star))  %>%
arrange(desc(wage_star))
View(df)
set.seed(7)
df <- tibble(z = runif(1000),
x = runif(1000),
uv = rmvnorm(1000, mean = c(0, 0),
sigma = rbind(c(1, 0.7), c(0.7, 1))),
i_star = 4 - 5 * z + uv[, 1],
y_star = 6 - 3 * x + uv[, 2],
y = ifelse(i_star > 0, y_star, 0)) # this is a selection mechanism
View(df)
df %>%
slice(c(1:5)) %>%
knitr::kable()
df %>%
slice(1:5) %>%
knitr::kable()
set.seed(7)
df <- tibble(z = runif(1000),
x = runif(1000),
uv = rmvnorm(1000, mean = c(0, 0),
sigma = rbind(c(1, 0.7), c(0.7, 1))),
i_star = 4 - 5 * z + uv[, 1],
y_star = 6 - 3 * x + uv[, 2],
y = ifelse(i_star > 0, y_star, 0)) # this is a selection mechanism
df %>%
slice(1:5) %>%
knitr::kable()
View(df)
df[c(1:5),] %>%
knitr::kable()
library(mvtnorm) # to simulate bivariate normal random variable
set.seed(7)
df <- tibble(z = runif(1000),
x = runif(1000),
uv = rmvnorm(1000, mean = c(0, 0),
sigma = rbind(c(1, 0.7), c(0.7, 1))),
i_star = 4 - 5 * z + uv[, 1],
y_star = 6 - 3 * x + uv[, 2],
y = ifelse(i_star > 0, y_star, 0)) # this is a selection mechanism
df[c(1:5),] %>%
knitr::kable()
df[,c(1:5)] %>%
knitr::kable()
df %>%
slice(c(997:1000, 1:4)) %>%
knitr::kable()
# Always set seed so you can replicate your results
set.seed(7)
df <- tibble(education = runif(1000, 5, 15),
wage_star = 1000 + 200*education + rnorm(1000, 0, 100),
wage = ifelse(wage_star > 3500, 3500, wage_star))  %>%
arrange(desc(wage_star))
df %>%
slice(c(997:1000, 1:4)) %>%
knitr::kable()
df <- tibble(education = runif(1000, 5, 15),
wage_star = 1000 + 200*education + rnorm(1000, 0, 100),
wage = ifelse(wage_star > 3500, 3500, wage_star))  %>%
arrange(desc(-wage_star))
df %>%
slice(c(1:4, 997:1000)) %>%
knitr::kable()
library(mvtnorm) # to simulate bivariate normal random variable
set.seed(7)
df <- tibble(z = runif(1000),
x = runif(1000),
uv = rmvnorm(1000, mean = c(0, 0),
sigma = rbind(c(1, 0.7), c(0.7, 1))),
i_star = 4 - 5 * z + uv[, 1],
y_star = 6 - 3 * x + uv[, 2],
y = ifelse(i_star > 0, y_star, 0)) # this is a selection mechanism
df %>%
slice(c(1:4, 997:1000)) %>%
knitr::kable()
head(df) %>%
knitr::kable()
View(df)
head(df)
head(df)
df <- tibble(z = runif(1000),
x = runif(1000),
uv = rmvnorm(1000, mean = c(0, 0),
sigma = rbind(c(1, 0.7), c(0.7, 1))),
i_star = 4 - 5 * z + uv[, 1],
y_star = 6 - 3 * x + uv[, 2],
y = ifelse(i_star > 0, y_star, 0)) # this is a selection mechanism
head(df)
head(df)
head(df)
View(df)
head(df)
head(df)
library(mvtnorm) # to simulate bivariate normal random variable
set.seed(7)
df <- tibble(z = runif(1000),
x = runif(1000),
uv = rmvnorm(1000, mean = c(0, 0),
sigma = rbind(c(1, 0.7), c(0.7, 1))),
i_star = 4 - 5 * z + uv[, 1],
y_star = 6 - 3 * x + uv[, 2],
y = ifelse(i_star > 0, y_star, 0)) # this is a selection mechanism
head(df)
head(df) %>%
knitr::kable()
head(df) %>%
kable()
?tibble
?arrange
# Always set seed so you can replicate your results
set.seed(7)
df <- tibble(education = runif(1000, 5, 15),
wage_star = 1000 + 200*education + rnorm(1000, 0, 100),
wage = ifelse(wage_star > 3500, 3500, wage_star))  %>%
arrange(desc(-wage_star))
df %>%
slice(c(1:4, 997:1000)) %>%
knitr::kable()
# Always set seed so you can replicate your results
set.seed(7)
df <- tibble(education = runif(1000, 5, 15),
wage_star = 1000 + 200*education + rnorm(1000, 0, 100),
wage = ifelse(wage_star > 3500, 3500, wage_star))  %>%
arrange(-wage_star)
df %>%
slice(c(1:4, 997:1000)) %>%
knitr::kable()
df <- tibble(education = runif(1000, 5, 15),
wage_star = 1000 + 200*education + rnorm(1000, 0, 100),
wage = ifelse(wage_star > 3500, 3500, wage_star))  %>%
arrange(wage_star)
df %>%
slice(c(1:4, 997:1000)) %>%
knitr::kable()
set.seed(7)
df <- tibble(x = seq(0, 1000, length.out = 1000),
# non-constant variance
sig = 0.1 + 0.05*x,
y = 6 + 0.1*x + rnorm(1000, mean = 0, sd = sig))
library(mvtnorm) # to simulate bivariate normal random variable
set.seed(7)
df <- tibble(z = runif(1000),
x = runif(1000),
uv = rmvnorm(1000, mean = c(0, 0),
sigma = rbind(c(2, 0.7),
c(0.7, 1))),
i_star = 4 - 5 * z + uv[, 1],
y_star = 6 - 3 * x + uv[, 2],
y = ifelse(i_star > 0, y_star, 0)) # this is a selection mechanism
head(df)
selection_equation <- glm(I(y > 0) ~ z, df, family = binomial(link = "probit"))
wage_equation <- lm(y ~ x, df)
msummary(list(selection_equation, wage_equation), stars = TRUE, gof_omit = '^(?!Num)')
?fitstat
lm(y ~ x, df)
ols_qr <- lm(y ~ x, df)
View(ols_qr)
set.seed(7)
df <- tibble(x = seq(0, 1000, length.out = 1000),
# non-constant variance
sig = 0.1 + 0.05*x,
y = 6 + 0.1*x + rnorm(1000, mean = 0, sd = sig))
ols_qr <- lm(y ~ x, df)
ols_qr[["coefficients"]][["x"]]
